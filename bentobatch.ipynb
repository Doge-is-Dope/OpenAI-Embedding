{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import tiktoken  # for counting tokens\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import string  # for removing punctuation\n",
    "import unicodedata  # for normalizing text\n",
    "import urllib.request  # for downloading html\n",
    "from bs4 import BeautifulSoup  # for parsing html\n",
    "from collections import deque\n",
    "from html.parser import HTMLParser\n",
    "from openai import OpenAI  # for calling the OpenAI API\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    wait_random_exponential,\n",
    "    stop_after_attempt,\n",
    ")  # for retrying API calls\n",
    "from urllib.parse import urlparse\n",
    "from utils.embeddings_utils import cosine_similarity\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "GPT_MODEL = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "domain = \"app.bentobatch.com\"\n",
    "full_url = \"https://app.bentobatch.com/\"\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl Web Pages\n",
    "\n",
    "Given a list of URLs, crawl each page and return the content of the page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex pattern to match a URL\n",
    "HTTP_URL_PATTERN = r\"^http[s]*://.+\"\n",
    "\n",
    "\n",
    "# Create a class to parse the HTML and get the hyperlinks\n",
    "class HyperlinkParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Create a list to store the hyperlinks\n",
    "        self.hyperlinks = []\n",
    "\n",
    "    # Override the HTMLParser's handle_starttag method to get the hyperlinks\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        attrs = dict(attrs)\n",
    "\n",
    "        # If the tag is an anchor tag and it has an href attribute, add the href attribute to the list of hyperlinks\n",
    "        if tag == \"a\" and \"href\" in attrs:\n",
    "            self.hyperlinks.append(attrs[\"href\"])\n",
    "\n",
    "\n",
    "# Function to get the hyperlinks from a URL\n",
    "def get_hyperlinks(url):\n",
    "\n",
    "    user_agent = \"Mozilla/5.0\"\n",
    "    headers = {\"User-Agent\": user_agent}\n",
    "\n",
    "    # Try to open the URL and read the HTML\n",
    "    try:\n",
    "        request = urllib.request.Request(url=url, headers=headers)\n",
    "        # Open the URL and read the HTML\n",
    "        with urllib.request.urlopen(request) as response:\n",
    "\n",
    "            # If the response is not HTML, return an empty list\n",
    "            if not response.info().get(\"Content-Type\").startswith(\"text/html\"):\n",
    "                return []\n",
    "\n",
    "            # Decode the HTML\n",
    "            html = response.read().decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "    # Create the HTML Parser and then Parse the HTML to get hyperlinks\n",
    "    parser = HyperlinkParser()\n",
    "    parser.feed(html)\n",
    "\n",
    "    return parser.hyperlinks\n",
    "\n",
    "\n",
    "# Function to get the hyperlinks from a URL that are within the same domain\n",
    "def get_domain_hyperlinks(local_domain, url):\n",
    "    clean_links = []\n",
    "    for link in set(get_hyperlinks(url)):\n",
    "        clean_link = None\n",
    "\n",
    "        # If the link is a URL, check if it is within the same domain\n",
    "        if re.search(HTTP_URL_PATTERN, link):\n",
    "            # Parse the URL and check if the domain is the same\n",
    "            url_obj = urlparse(link)\n",
    "            if url_obj.netloc == local_domain:\n",
    "                clean_link = link\n",
    "\n",
    "        # If the link is not a URL, check if it is a relative link\n",
    "        else:\n",
    "            if link.startswith(\"/\"):\n",
    "                link = link[1:]\n",
    "            elif link.startswith(\"#\") or link.startswith(\"mailto:\"):\n",
    "                continue\n",
    "            clean_link = \"https://\" + local_domain + \"/\" + link\n",
    "\n",
    "        if clean_link is not None:\n",
    "            if clean_link.endswith(\"/\"):\n",
    "                clean_link = clean_link[:-1]\n",
    "            clean_links.append(clean_link)\n",
    "\n",
    "    # Return the list of hyperlinks that are within the same domain\n",
    "    return list(set(clean_links))\n",
    "\n",
    "\n",
    "def crawl(url):\n",
    "    # Parse the URL and get the domain\n",
    "    local_domain = urlparse(url).netloc\n",
    "\n",
    "    # Create a queue to store the URLs to crawl\n",
    "    queue = deque([url])\n",
    "\n",
    "    # Create a set to store the URLs that have already been seen (no duplicates)\n",
    "    seen = set([url])\n",
    "\n",
    "    # Create a directory to store the text files\n",
    "    if not os.path.exists(\"text/\"):\n",
    "        os.mkdir(\"text/\")\n",
    "\n",
    "    if not os.path.exists(\"text/\" + local_domain + \"/\"):\n",
    "        os.mkdir(\"text/\" + local_domain + \"/\")\n",
    "\n",
    "    # Create a directory to store the csv files\n",
    "    if not os.path.exists(\"processed\"):\n",
    "        os.mkdir(\"processed\")\n",
    "\n",
    "    # While the queue is not empty, continue crawling\n",
    "    while queue:\n",
    "\n",
    "        # Get the next URL from the queue\n",
    "        url = queue.pop()\n",
    "        print(url)  # for debugging and to see the progress\n",
    "\n",
    "        # Save text from the url to a <url>.txt file\n",
    "        with open(\n",
    "            \"text/\" + local_domain + \"/\" + url[8:].replace(\"/\", \"_\") + \".txt\", \"w\"\n",
    "        ) as f:\n",
    "\n",
    "            # Get the text from the URL using BeautifulSoup\n",
    "            soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "\n",
    "            # Get the content from the URL\n",
    "            text = soup.get_text()\n",
    "\n",
    "            # Write the data to the file\n",
    "            f.write(text)\n",
    "\n",
    "        # Get the hyperlinks from the URL and add them to the queue\n",
    "        for link in get_domain_hyperlinks(local_domain, url):\n",
    "            if link not in seen:\n",
    "                queue.append(link)\n",
    "                seen.add(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.bentobatch.com/\n",
      "https://app.bentobatch.com/case/etf_ethereum_top10\n",
      "https://app.bentobatch.com/case/aave_usdt_eth\n",
      "https://app.bentobatch.com/case/scroll_airdrop_hunting_advanced\n",
      "https://app.bentobatch.com/case/pendle_points\n",
      "https://app.bentobatch.com/case/yearn_v3_usdt_a\n",
      "https://app.bentobatch.com/case/zircuit_ethena_usdt\n",
      "https://app.bentobatch.com/case/aave_eth_eth\n",
      "https://app.bentobatch.com/case/ether_fi_liquid\n",
      "https://app.bentobatch.com/case/yearn_v3_usdce\n",
      "https://app.bentobatch.com/case/zora_famous_creators\n",
      "https://app.bentobatch.com/case/zircuit_rsweth\n",
      "https://app.bentobatch.com/case/kelp_and_pendle\n",
      "https://app.bentobatch.com/case/yearn_v3_weth\n",
      "https://app.bentobatch.com/case/aerodrome_degen_liquidity\n",
      "https://app.bentobatch.com/case/scroll_airdrop_hunting_professional\n",
      "https://app.bentobatch.com/case/ethena_usdt\n",
      "https://app.bentobatch.com/case/ether_fi_arbitrum_bridge\n",
      "https://app.bentobatch.com\n",
      "https://app.bentobatch.com/case/zircuit_renzo\n",
      "https://app.bentobatch.com/case/gamma_yearn\n",
      "https://app.bentobatch.com/case/aave_eth_eth_emode\n",
      "https://app.bentobatch.com/case/zircuit_etherfi\n",
      "https://app.bentobatch.com/case/zircuit_eigenpie_swell\n",
      "https://app.bentobatch.com/case/scroll_airdrop_hunting_with_penpad\n",
      "https://app.bentobatch.com/case/zircuit_ethena_usdc\n",
      "https://app.bentobatch.com/case/scroll_airdrop_hunting_rookie\n",
      "https://app.bentobatch.com/case/yearn_withdrawal\n",
      "https://app.bentobatch.com/case/genesis_liquidity\n",
      "https://app.bentobatch.com/case/aave_usdc_eth\n",
      "https://app.bentobatch.com/dashboard\n",
      "https://app.bentobatch.com/case/yearn_v3_dai_a\n",
      "https://app.bentobatch.com/case/eigenpie_steth\n",
      "https://app.bentobatch.com/case/juice_points\n",
      "https://app.bentobatch.com/case/zora_most_minted\n",
      "https://app.bentobatch.com/case/orbit_points\n"
     ]
    }
   ],
   "source": [
    "crawl(full_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    \"\"\"Remove newlines from a pandas series for better processing.\"\"\"\n",
    "    serie = serie.str.replace(\"\\n\", \" \")\n",
    "    serie = serie.str.replace(\"\\\\n\", \" \")\n",
    "    serie = serie.str.replace(\"  \", \" \")\n",
    "    serie = serie.str.replace(\"  \", \" \")\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the data records\n",
    "data = []\n",
    "\n",
    "# Get all the text files in the text directory\n",
    "for file in os.listdir(\"text/\" + domain + \"/\"):\n",
    "\n",
    "    # Open the file and read the text\n",
    "    with open(\"text/\" + domain + \"/\" + file, \"r\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "        # Omit the first 11 lines and the last 4 lines, then replace -, _, and #update with spaces.\n",
    "        data.append(\n",
    "            (\n",
    "                file[len(domain) + 6 : -4]\n",
    "                .replace(\"-\", \" \")\n",
    "                .replace(\"_\", \" \")\n",
    "                .replace(\"#update\", \"\"),\n",
    "                text,\n",
    "            )\n",
    "        )\n",
    "# Create a dataframe from the list of texts\n",
    "df = pd.DataFrame(data, columns=[\"fname\", \"text\"])\n",
    "df[\"text\"] = df.fname + \". \" + remove_newlines(df.text)\n",
    "df.to_csv(\"processed/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def get_embedding(text: str, model=EMBEDDING_MODEL):\n",
    "    # replace newlines, which can negatively affect performance.\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pendle points</td>\n",
       "      <td>pendle points. Bento Batch | One Click. All se...</td>\n",
       "      <td>[-0.017359748482704163, -9.767817391548306e-05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zora most minted</td>\n",
       "      <td>zora most minted. Bento Batch | One Click. All...</td>\n",
       "      <td>[-0.0002776383771561086, 0.0015714016044512391...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genesis liquidity</td>\n",
       "      <td>genesis liquidity. Bento Batch | One Click. Al...</td>\n",
       "      <td>[-0.006265711970627308, -0.005031391978263855,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scroll airdrop hunting rookie</td>\n",
       "      <td>scroll airdrop hunting rookie. Bento Batch | O...</td>\n",
       "      <td>[-0.013905385509133339, -0.02448737621307373, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zora famous creators</td>\n",
       "      <td>zora famous creators. Bento Batch | One Click....</td>\n",
       "      <td>[0.018052520230412483, 0.0011609457433223724, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           fname  \\\n",
       "0                  pendle points   \n",
       "1               zora most minted   \n",
       "2              genesis liquidity   \n",
       "3  scroll airdrop hunting rookie   \n",
       "4           zora famous creators   \n",
       "\n",
       "                                                text  \\\n",
       "0  pendle points. Bento Batch | One Click. All se...   \n",
       "1  zora most minted. Bento Batch | One Click. All...   \n",
       "2  genesis liquidity. Bento Batch | One Click. Al...   \n",
       "3  scroll airdrop hunting rookie. Bento Batch | O...   \n",
       "4  zora famous creators. Bento Batch | One Click....   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.017359748482704163, -9.767817391548306e-05...  \n",
       "1  [-0.0002776383771561086, 0.0015714016044512391...  \n",
       "2  [-0.006265711970627308, -0.005031391978263855,...  \n",
       "3  [-0.013905385509133339, -0.02448737621307373, ...  \n",
       "4  [0.018052520230412483, 0.0011609457433223724, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embedding\"] = df[\"text\"].apply(lambda x: get_embedding(x))\n",
    "df.to_csv(\"processed/embeddings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: cosine_similarity(x, y),\n",
    "    top_n: int = 100,\n",
    "):\n",
    "    # Get the embedding for the query\n",
    "    query_embedding = get_embedding(query)\n",
    "\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples\n",
    "# strings, relatednesses = search_functions(\"AAVE related\", df, top_n=5)\n",
    "# for string, relatedness in zip(strings, relatednesses):\n",
    "#     print(f\"{relatedness=:.3f}\")\n",
    "#     display(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(query: str, df: pd.DataFrame, model: str, token_budget: int) -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatedness = search_relatedness(query, df)\n",
    "    introduction = 'You are a member of BentoBatch. Use the provided data to answer the subsequent question. If the answer cannot be found in the data, write \"I don\\'t know.\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        data = f'\\n\\nData:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if num_tokens(message + data + question, model=model) > token_budget:\n",
    "            break\n",
    "        else:\n",
    "            message += data\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You answer questions about the cases on BentoBatch.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, messages=messages, temperature=0\n",
    "    )\n",
    "    response_message = response.choices[0].message.content\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bento Batch is a Streamlined Transaction Layer (STL) that leverages Account Abstraction techniques to upscale blockchain efficiency, providing an easier, cheaper, and safer on-chain experience.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is BentoBatch?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BentoBox is a reward system in Bento Batch. Users can earn Bento Boxes by executing a Batch, with higher gas fees, more transactions per Batch, and larger volume input resulting in more Bento Boxes as rewards. Additionally, users can refer friends and receive an additional 10% of their friends' Bento Boxes as a bonus.\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is BentoBox?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BentoBatch provides a streamlined transaction layer (STL) that consolidates multiple on-chain interactions into a single transaction. This means you no longer need to sign each transaction individually or understand every transaction detail. Instead, you define your objectives, and BentoBatch facilitates your needs efficiently with just one click. This makes the on-chain experience easier, cheaper, and safer.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"Why do I need BentoBatch if I can interact with the dApps directly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cases related to AAVE are:\\n\\n1. **aave eth eth. Bento Batch | One Click. All set.**\\n   - Deposit ETH and borrow ETH on AAVE [Normal-Mode]\\n   \\n2. **aave eth eth emode. Bento Batch | One Click. All set.**\\n   - Deposit ETH and borrow ETH on AAVE [E-Mode]\\n   \\n3. **aave usdc eth. Bento Batch | One Click. All set.**\\n   - Deposit USDC to borrow ETH on AAVE\\n   \\n4. **aave usdt eth. Bento Batch | One Click. All set.**\\n   - Deposit USDT to borrow ETH on AAVE'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What cases are related to AAVE?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following cases are official collaborations:\\n\\n1. **Ether.fi**:\\n   - Earn extra Ether.Fi points and BridgeEthereum\\n   - Stake ETH to EtherFi and Zircuit to earn Zircuit points, EtherFi loyalty points, and EigenLayer Points\\n\\n2. **Swell**:\\n   - Earn extra 15% Zircuit Points with Swell Restaking\\n\\n3. **Ethena**:\\n   - Earn extra 15% Zircuit Points with Ethena Restaking by USDC\\n   - Earn extra 15% Zircuit Points with Ethena Restaking by USDT\\n\\n4. **Renzo**:\\n   - Earn extra 15% Zircuit Points with Renzo Restaking by ETH\\n\\n5. **Penpad**:\\n   - Earn extra 10% Penpad Points and share up to 10000 $BLT prize pool\\n\\n6. **Genesis**:\\n   - Earn extra 20% GenesisLRT restaking points and get x15 Gems boost\\n\\n7. **Zircuit**:\\n   - Restake with Eigenpie & Swell & Zircuit'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What cases are official collaborations?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You have several options for using your USDC on BentoBatch:\\n\\n1. **Deposit USDC to borrow ETH on AAVE**:\\n   - Deposit USDC and borrow up to 70% equivalent value in ETH.\\n   - Interact with AAVE contracts to supply USDC as collateral and borrow ETH.\\n\\n2. **Earn extra 15% Zircuit Points with Ethena Restaking by USDC**:\\n   - Swap USDC to USDe and deposit USDe on Zircuit.\\n   - Interact with Curve and Zircuit contracts for swapping and staking.\\n\\n3. **Yield farming on Yearn with USDC.e**:\\n   - Deposit USDC.e to Yearn financeâ€™s V3 Vault for auto compounding and high APY.\\n   - Interact with Yearn V3 contracts to approve and deposit USDC.e.\\n\\n4. **Yield Farming on Yearn with Gamma USDC.e/WETH LP**:\\n   - Provide USDC.e/WETH LP on Gamma and reinvest it on Yearn V3 vaults.\\n   - Interact with 1inch, Gamma Vault, and Yearn V3 contracts for swapping, approving, and depositing.\\n\\n5. **On-chain Interaction on Scroll: Professional**:\\n   - Swap, wrap, unwrap, lend, and borrow using USDC.\\n   - Interact with various contracts on Scroll for different DeFi activities.\\n\\n6. **On-chain Interaction on Scroll: Advanced**:\\n   - Similar to the professional option but with fewer interactions and slightly lower potential.\\n\\nChoose the option that best fits your investment strategy and risk tolerance.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"I have a plenty of usdc, what can I do with it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The point system on BentoBatch is used to reward users for engaging in various DeFi activities such as staking, restaking, swapping, lending, and providing liquidity. Users can earn different types of points like Kelp Miles, Renzo ezPoints, EigenLayer Points, Juice Finance Points, Zircuit Points, EtherFi loyalty points, Blast Points, and more, depending on the specific strategy or platform they interact with. These points can be accumulated and potentially used for benefits or rewards within the BentoBatch ecosystem.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is the point system used for?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"Is it safe to use BentoBatch?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know. The provided data does not contain any information or details about the tokenomics of the project.\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"How do you think this project should develop its tokenomics?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
